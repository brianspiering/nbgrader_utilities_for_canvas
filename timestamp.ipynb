{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.datetime(2013,9,1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1378033200.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = (dt - datetime.datetime(1970,1,1)).total_seconds()\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2013, 9, 1, 11, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.utcfromtimestamp(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt2 = os.path.getmtime('lorem.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1541433214.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 11, 5, 15, 53, 34)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.utcfromtimestamp(dt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1541340000.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt3 = datetime.datetime(2018,11,4,14)\n",
    "i3 = (dt3 - datetime.datetime(1970,1,1)).total_seconds()\n",
    "i3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 12, 1, 14, 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.utcfromtimestamp(i3) + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2 > i3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 11, 5, 14, 0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt3 = datetime.datetime(2018,11,4,14) + datetime.timedelta(days=1)\n",
    "dt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shen/Desktop/USF/assignments/utilities'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shen/Desktop/USF/assignments'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nbgrader.api import Gradebook, MissingEntry\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'sqlite:///../gradebook.db'\n",
    "selected_as = 'naive_bayes_lab'\n",
    "grades_file = '../scores/' + selected_as +'/' + 'grades.csv' \n",
    "student_id = pd.read_csv('students_raw.csv').drop([0])\n",
    "student_id = student_id[['ID', 'SIS User ID', 'SIS Login ID']]\n",
    "id_col = 'SIS Login ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_score(data_url, selected_as, grades_file, student_id, id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_score(database_url, selected_assignment, grades_file, student_id, id_col):\n",
    "    \"\"\"\n",
    "    pull score from db and save into a csv\n",
    "    \"\"\"\n",
    "\n",
    "    with Gradebook(database_url) as gb:\n",
    "        \n",
    "        grades = []\n",
    "        \n",
    "        for assignment in gb.assignments:\n",
    "            # only pull scores of the selected assignment\n",
    "            if assignment.name == selected_assignment:\n",
    "\n",
    "                for student in gb.students:\n",
    "                    score ={}\n",
    "                    score['max_score'] = assignment.max_score\n",
    "                    score['student'] = student.id\n",
    "                    score['assignment'] = assignment.name\n",
    "                    \n",
    "                    try:\n",
    "                        submission = gb.find_submission(assignment.name, student.id)\n",
    "                    except MissingEntry: \n",
    "                        score['score'] = 0.0\n",
    "                    else:\n",
    "                        score['score'] = submission.score\n",
    "\n",
    "                    grades.append(score)\n",
    "\n",
    "    # Create a pandas dataframe with our score information, and save it to disk\n",
    "    grades = pd.DataFrame(grades)\n",
    "    \n",
    "    # merge the score information with sis_id from df of student_id\n",
    "    grades_info = pd.merge(grades, student_id, left_on='student', right_on=id_col, how='left')\n",
    "    \n",
    "    # save the grades\n",
    "    grades_info.to_csv(grades_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../autograded/'\n",
    "folder = 'naive_bayes_lab'\n",
    "run = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_files(path, folder, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_files(path, folder_name, run):\n",
    "    \"\"\"\n",
    "    delete previous submitted/graded versions\n",
    "    \"\"\"\n",
    "    if run == 'True': # identify to delete or not\n",
    "\n",
    "        if os.path.exists(path): # if path doesn't exist, no need to delete\n",
    "        # path = '../autograded/'\n",
    "            folders = os.listdir(path)\n",
    "\n",
    "            # delete the previous graded information\n",
    "            for folder in folders:\n",
    "\n",
    "                try:\n",
    "                    shutil.rmtree(path+folder+'/'+folder_name)\n",
    "                except (FileNotFoundError, NotADirectoryError):\n",
    "                    pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.read_csv('../scores/naive_bayes_lab/grades.csv')\n",
    "with open('../scores/'+'naive_bayes_lab'+'/summary.txt', \"a\") as f:\n",
    "    \n",
    "        f.write('\\n')\n",
    "        f.write('---score summary---\\n')\n",
    "        f.write('min    : ' +  str(min(score_df['score']))+'\\n' )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../scores/naive_bayes_lab/summary.txt', 'a') as f:\n",
    "    f.write('hey')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
